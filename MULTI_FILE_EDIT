// app/api/chat/route.ts
import { google } from '@ai-sdk/google';
import { streamText, type ModelMessage } from 'ai';

export const maxDuration = 60;

type Body = {
messages: { role: 'user' | 'assistant'; content: string }[];
mode: 'normal' | 'bf' | 'gf';
lang: 'auto' | 'english' | 'hinglish' | 'marwadi';
imageInputs?: { name: string; dataUrl: string }[];
nonImageContext?: string;
model?: string;   // e.g. 'gemini-2.5-pro'
strict?: boolean; // if true, do not fallback
};

function systemPrompt(mode: Body['mode'], lang: Body['lang']) {
const persona =
  mode === 'normal'
    ? 'You are TPyaar, a helpful, knowledgeable assistant.'
    : mode === 'bf'
    ? 'You are TPyaar in Boyfriend mode: warm, supportive, playful, flirty (PG-13).'
    : 'You are TPyaar in Girlfriend mode: caring, empathetic, playful, flirty (PG-13).';
const safety =
  'Be respectful, avoid explicit sexual content, illegal activity, self-harm instructions, hate or harassment. Refuse unsafe requests. Keep conversations consensual and age-appropriate.';
const langPref =
  lang === 'auto'
    ? 'Detect and match the user language, or follow explicit language commands.'
    : lang === 'english'
    ? 'Respond in English.'
    : lang === 'hinglish'
    ? 'Respond in Hinglish (mix of Hindi and English).'
    : 'Respond in Marwadi.';
return `${persona}\n${langPref}\n${safety}`;
}

// Reduce tokens: keep last 12 turns (24 messages max)
function clampHistory(messages: Body['messages']) {
const MAX = 24;
return messages.length <= MAX ? messages : messages.slice(-MAX);
}

export async function POST(req: Request) {
const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY;
const body = (await req.json()) as Body;

if (!apiKey) {
  return new Response(
    'Setup: Please add GOOGLE_GENERATIVE_AI_API_KEY to enable Gemini.',
    { status: 200 }
  );
}

const {
  messages,
  mode,
  lang,
  imageInputs,
  nonImageContext,
  model = 'gemini-2.5-pro',
  strict = false,
} = body;

const imgContext = imageInputs?.length
  ? `User attached ${imageInputs.length} image(s). Provide helpful analysis.`
  : '';
const extraCtx = nonImageContext ? `\nNon-image attachments: ${nonImageContext}` : '';

const clamped = clampHistory(messages);
const modelMessages: ModelMessage[] = [
  { role: 'system', content: systemPrompt(mode, lang) },
  ...(imgContext ? [{ role: 'user', content: imgContext + extraCtx }] : []),
  ...clamped.map(m => ({ role: m.role, content: m.content })),
];

// Primary: gemini-2.5-pro. Optional fallbacks (can be disabled with strict=true).
const tryModels = strict
  ? [model]
  : [model, 'gemini-2.5-flash', 'gemini-1.5-pro', 'gemini-1.5-flash'] as const;

let lastErr: any = null;
for (const modelName of tryModels) {
  try {
    const result = streamText({
      model: google(modelName, { apiKey }),
      messages: modelMessages,
    });
    return result.toTextStreamResponse();
  } catch (err) {
    lastErr = err;
    continue;
  }
}

const reason =
  typeof lastErr?.message === 'string'
    ? lastErr.message
    : 'Rate limit or quota exceeded.';
const help =
  'Provider limits reached. Please try again shortly or disable strict mode to allow fallbacks.';
return new Response(`TPyaar notice: ${help}\n\nDetails: ${reason}`, {
  status: 200,
});
}

// app/api/analyze-image/route.ts
export const maxDuration = 60;

type Body = {
dataUrl: string;
prompt?: string;
mode: 'normal' | 'bf' | 'gf';
lang: 'auto' | 'english' | 'hinglish' | 'marwadi';
model?: string;   // e.g. 'gemini-2.5-pro'
strict?: boolean; // disable fallbacks
};

function systemPrompt(mode: Body['mode'], lang: Body['lang']) {
const persona =
  mode === 'normal'
    ? 'You are TPyaar, a helpful, knowledgeable assistant.'
    : mode === 'bf'
    ? 'You are TPyaar in Boyfriend mode: warm, supportive, playful, flirty (PG-13).'
    : 'You are TPyaar in Girlfriend mode: caring, empathetic, playful, flirty (PG-13).';
const safety =
  'Be respectful, avoid explicit sexual content, illegal activity, self-harm instructions, hate or harassment. Refuse unsafe requests. Keep conversations consensual and age-appropriate.';
const langPref =
  lang === 'auto'
    ? 'Detect and match the user language, or follow explicit language commands.'
    : lang === 'english'
    ? 'Respond in English.'
    : lang === 'hinglish'
    ? 'Respond in Hinglish (mix of Hindi and English).'
    : 'Respond in Marwadi.';
return `${persona}\n${langPref}\n${safety}`;
}

async function callGeminiImage(
apiKey: string,
model: string,
mime: string,
b64: string,
contentText: string
) {
const url = `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(
  model
)}:generateContent?key=${encodeURIComponent(apiKey)}`;

const payload = {
  contents: [
    {
      role: 'user',
      parts: [
        { text: contentText },
        {
          inline_data: {
            mime_type: mime,
            data: b64,
          },
        },
      ],
    },
  ],
};

const res = await fetch(url, {
  method: 'POST',
  headers: { 'content-type': 'application/json' },
  body: JSON.stringify(payload),
});

if (!res.ok) {
  const t = await res.text();
  throw new Error(t);
}

const json = (await res.json()) as any;
const text =
  json?.candidates?.[0]?.content?.parts?.map((p: any) => p.text).join('') ||
  json?.candidates?.[0]?.content?.parts?.[0]?.text ||
  'No description was returned.';
return text;
}

export async function POST(req: Request) {
try {
  const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY;
  if (!apiKey) {
    return new Response(
      JSON.stringify({ text: 'Setup: Add GOOGLE_GENERATIVE_AI_API_KEY to enable image analysis.' }),
      { status: 200 }
    );
  }
  const { dataUrl, prompt, mode, lang, model = 'gemini-2.5-pro', strict = false } = (await req.json()) as Body;

  const match = dataUrl.match(/^data:(.+);base64,(.*)$/);
  if (!match) {
    return new Response(JSON.stringify({ text: 'Invalid image data (expected data URL)' }), { status: 200 });
  }
  const mime = match[1];
  const b64 = match[2];

  const contentText = systemPrompt(mode, lang) + '\n\nTask: ' + (prompt || 'Describe this image and provide insights.');

  const tryModels = strict
    ? [model]
    : [model, 'gemini-2.5-flash', 'gemini-1.5-pro', 'gemini-1.5-flash'];

  let lastErr: any = null;
  for (const m of tryModels) {
    try {
      const text = await callGeminiImage(apiKey, m, mime, b64, contentText);
      return new Response(JSON.stringify({ text }), { status: 200 });
    } catch (e) {
      lastErr = e;
      continue;
    }
  }
  return new Response(
    JSON.stringify({
      text:
        'Image analysis temporarily unavailable due to provider limits. Please try again later.',
      details: String(lastErr?.message || ''),
    }),
    { status: 200 }
  );
} catch (e: any) {
  return new Response(JSON.stringify({ text: `Image analysis error: ${e?.message || 'Unknown error'}` }), {
    status: 200,
  });
}
}

// app/api/video/storyboard/route.ts
import { google } from '@ai-sdk/google';
import { generateText } from 'ai';

export const maxDuration = 60;

type Body = {
prompt: string;
mode: 'normal' | 'bf' | 'gf';
lang: 'auto' | 'english' | 'hinglish' | 'marwadi';
model?: string;   // e.g. 'gemini-2.5-pro'
strict?: boolean; // disable fallbacks
};

function sysPrompt(mode: Body['mode'], lang: Body['lang']) {
const persona =
  mode === 'normal'
    ? 'You are TPyaar, a helpful assistant.'
    : mode === 'bf'
    ? 'You are TPyaar (Boyfriend mode): warm, supportive, playful (PG-13).'
    : 'You are TPyaar (Girlfriend mode): caring, empathetic, playful (PG-13).';
const langPref =
  lang === 'auto'
    ? 'Write captions in the user language; if not obvious, use English.'
    : lang === 'english'
    ? 'Write captions in English.'
    : lang === 'hinglish'
    ? 'Write captions in Hinglish.'
    : 'Write captions in Marwadi.';
return `${persona}\n${langPref}\nCreate a short storyboard (4-6 scenes). Provide a JSON array of objects with { title, caption } pairs.`;
}

async function tryGenerate(apiKey: string, modelName: string, prompt: string, system: string) {
const { text } = await generateText({
  model: google(modelName, { apiKey }),
  system,
  prompt: `Prompt: ${prompt}\nReturn ONLY valid JSON array: [{"title":"...", "caption":"..."}]`,
});
return text;
}

export async function POST(req: Request) {
const apiKey = process.env.GOOGLE_GENERATIVE_AI_API_KEY;
const { prompt, mode, lang, model = 'gemini-2.5-pro', strict = false } = (await req.json()) as Body;

if (!apiKey) {
  const frames = [
    { title: 'Scene 1', caption: `Intro: ${prompt.slice(0, 60)}...` },
    { title: 'Scene 2', caption: 'Key idea 1 explained simply.' },
    { title: 'Scene 3', caption: 'Key idea 2 with an example.' },
    { title: 'Scene 4', caption: 'Conclusion and call-to-action.' },
  ];
  return new Response(JSON.stringify({ frames }), { status: 200 });
}

const system = sysPrompt(mode, lang);
const models = strict ? [model] : [model, 'gemini-2.5-flash', 'gemini-1.5-pro', 'gemini-1.5-flash'];

let text = '';
let ok = false;
for (const m of models) {
  try {
    text = await tryGenerate(apiKey, m, prompt, system);
    ok = true;
    break;
  } catch {
    ok = false;
    continue;
  }
}

let frames: { title: string; caption: string }[] = [];
if (ok) {
  try {
    const jsonStart = text.indexOf('[');
    const jsonEnd = text.lastIndexOf(']');
    const slice = jsonStart >= 0 && jsonEnd >= 0 ? text.slice(jsonStart, jsonEnd + 1) : text;
    frames = JSON.parse(slice);
  } catch {
    // fall through to default frames
  }
}
if (!frames.length) {
  frames = [
    { title: 'Scene 1', caption: `Intro: ${prompt.slice(0, 60)}...` },
    { title: 'Scene 2', caption: 'Key idea 1.' },
    { title: 'Scene 3', caption: 'Key idea 2.' },
    { title: 'Scene 4', caption: 'Conclusion.' },
  ];
}
if (frames.length < 4) {
  frames.push({ title: 'Scene 5', caption: 'Additional insight.' });
} else if (frames.length > 6) {
  frames = frames.slice(0, 6);
}

return new Response(JSON.stringify({ frames }), { status: 200 });
}

// app/page.tsx
// Assuming this is a React component, here's how to update the relevant functions:

// In handleSubmit():
// Replace the body JSON with:
/*
body: JSON.stringify({
mode,
lang: nextLang,
model: 'gemini-2.5-pro',
strict: false, // set to true to forbid fallbacks
messages: [
  ...nextMsgs.map(m => ({
    role: m.role,
    content: m.text,
  })),
],
imageInputs: imageBlobs,
nonImageContext: nonImageRefs || undefined,
}),
*/

// In analyzeImage():
// Add model and strict to the POST body:
/*
body: JSON.stringify({
dataUrl,
prompt: customPrompt || 'Describe this image in detail and answer any implied question.',
lang,
mode,
model: 'gemini-2.5-pro',
strict: false,
}),
*/

// In generateVideoFromPrompt():
// POST to storyboard with model/strict:
/*
body: JSON.stringify({
prompt,
lang,
mode,
model: 'gemini-2.5-pro',
strict: false,
}),
*/

// app/chat/page.tsx
// Replace the lucide-react import line so it no longer imports Wand2 or Video:
// import { Moon, Sun, Mic, StopCircle, Upload, Copy, Trash2, Download, Maximize2, Volume2, VolumeX, Clipboard } from 'lucide-react';
// Replace the Button group inside the form (just below the Textarea) with this version that only keeps Upload, Voice, and Send:

// app/page.tsx (welcome/sign-in page), update the subtitle to keep “with chat voice” and remove “media”.
// Replace the paragraph under CardTitle with:
/*
<p className="text-white/80">
Your colorful AI companion with chat voice.
</p>
*/
